---
title: "model3"
author: "Yuhe"
date: "2022-12-16"
output: pdf_document
---

```{r}
library(readr)
df = read.csv(file = "C:/Users/liuyu/Downloads/radiomics_completedata (2).csv")
df$Failure.binary = as.factor(df$Failure.binary)
df$Institution = as.factor(df$Institution)
head(df)

#Check for null and missing values 
is.na(df)
colSums(is.na(df))
df <- na.omit(df)
#df <- na.omit(df)
#Check for normality, if not, normalized the data 
summary(df)

df_norm <- scale(df[-c(1:2)])
summary(df_norm)
head(df_norm)

#df_final<- cbind(df['Failure.binary'], df_norm)
#head(df_final)
```


```{r}
library(dplyr)       # for data manipulation
library(ggplot2)     # for data visualization
library(stringr)     # for string functionality
library(gridExtra)   # for manipulaiting the grid
library(tidyverse)  # data manipulation
library(cluster)     # for general clustering algorithms
library(factoextra)  # for visualizing cluster results
library(mclust)
#Determining Optimal Number of Clusters
set.seed(123)

#function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(df_norm, k, nstart = 10)$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:15

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
     type="b", pch = 19, frame = FALSE, 
     xlab="Number of clusters K",
     ylab="Total within-clusters sum of squares")

# compute gap statistic
set.seed(123)
gap_stat <- clusGap(df_norm, FUN = kmeans, nstart = 25,
                    K.max = 10, B = 50)
# Print the result
print(gap_stat, method = "firstmax")

fviz_gap_stat(gap_stat)

# Compute k-means clustering with k = 2
set.seed(123)
final <- kmeans(df_norm, 2, nstart = 25)
print(final)

#final data
fviz_cluster(final, data = df_norm)
```

```{r}

##################################### Hierarchical ###########################
# Plot cluster results
p1 <- fviz_nbclust(df_norm, FUN = hcut, method = "wss", 
                   k.max = 10) +
  ggtitle("(A) Elbow method")
p2 <- fviz_nbclust(df_norm, FUN = hcut, method = "silhouette", 
                   k.max = 10) +
  ggtitle("(B) Silhouette method")
p3 <- fviz_nbclust(df_norm, FUN = hcut, method = "gap_stat", 
                   k.max = 10) +
  ggtitle("(C) Gap statistic")

# Display plots side by side
gridExtra::grid.arrange(p1, p2, p3, nrow = 1)
```
  
```{r}
# Construct dendorgram
library(StatMatch)
hc5 <- hclust(daisy(df_norm, metric = "gower"), method = "ward.D2" )
dend_plot <- fviz_dend(hc5)
dend_data <- attr(dend_plot, "dendrogram")
dend_cuts <- cut(dend_data, h = 2)
fviz_dend(dend_cuts$lower[[2]])

# Ward's method
hc5 <- hclust(daisy(df_norm, metric = "gower"), method = "ward.D2" )

# Cut tree into 4 groups
sub_grp <- cutree(hc5, k = 2)

# Number of members in each cluster
table(sub_grp)

# Plot full dendogram
fviz_dend(
  hc5,
  k = 2,
  horiz = TRUE,
  rect = TRUE,
  rect_fill = TRUE,
  rect_border = "jco",
  k_colors = "jco",
  cex = 0.1
)
```

```{r}
##################### Model-based ############################################
# Apply GMM model with 3 components

arrest_mc <- Mclust(df_norm, G = 3)

# Plot results
#par(mar = c(1, 1, 1, 1))
#plot(1:30)
```

```{r eval=FALSE}
plot(1:100000) 
plot(arrest_mc, what = "density")
plot(arrest_mc, what = "uncertainty")
#Error in plot.new() : figure margins too large
```

```{r}
# Observations with high uncertainty
sort(arrest_mc$uncertainty, decreasing = TRUE) %>% head()


summary(arrest_mc)

arrest_optimal_mc <- Mclust(df_norm)

summary(arrest_optimal_mc)

legend_args <- list(x = "bottomright", ncol = 5)
```

```{r eval=FALSE}
par(mar=c(1,1,1,1))
plot(arrest_optimal_mc, what = 'BIC', legendArgs = legend_args)
plot(arrest_optimal_mc, what = 'classification')
plot(arrest_optimal_mc, what = 'uncertainty')
#Error in plot.new() : figure margins too large
```

```{r}
df_mc <- Mclust(df_norm, 1:20)

summary(df_mc)

plot(df_mc, what = 'BIC', 
     legendArgs = list(x = "bottomright", ncol = 5))

probabilities <- df_mc$z 

probabilities <- probabilities %>%
  as.data.frame() %>%
  mutate(id = row_number()) %>%
  tidyr::gather(cluster, probability, -id)

ggplot(probabilities, aes(probability)) +
  geom_histogram() +
  facet_wrap(~ cluster, nrow = 2)

uncertainty <- data.frame(
  id = 1:nrow(df_norm),
  cluster = df_mc$classification,
  uncertainty = df_mc$uncertainty
)

uncertainty %>%
  group_by(cluster) %>%
  filter(uncertainty > 0.0001) %>%
  ggplot(aes(uncertainty, reorder(id, uncertainty))) +
  geom_point() +
  facet_wrap(~ cluster, scales = 'free_y', nrow = 1)


cluster2 <- df_norm %>%
  scale() %>%
  as.data.frame() %>%
  mutate(cluster = df_mc$classification) %>%
  filter(cluster == 2) %>%
  select(-cluster)

cluster2 %>%
  tidyr::gather(product, std_count) %>%
  group_by(product) %>%
  summarize(avg = mean(std_count)) %>%
  ggplot(aes(avg, reorder(product, avg))) +
  geom_point() +
  labs(x = "Average standardized consumption", y = NULL)
```